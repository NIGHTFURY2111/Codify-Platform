# -*- coding: utf-8 -*-
"""DeepNeuralNetwork_MNIST.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/19ggEwug2tbjVzJmZU300-eRckprzE3KI
"""

import torch
import torch.nn as nn
import torchvision
import torchvision.transforms as transforms
import matplotlib.pyplot as plt
import sys
from torch.utils.tensorboard import SummaryWriter
writer = SummaryWriter("runs/mnist")

# hyperparameters
input_size = 784
hidden_size = 100
num_classes = 10  # it can be 0 to 9
num_epoch = 2
batch_size = 100
learning_rate = 0.001

# load dataset
train_dataset = torchvision.datasets.MNIST(root='./data',train=True,transform=transforms.ToTensor(),download=True)
test_dataset = torchvision.datasets.MNIST(root='./data',train=False,transform=transforms.ToTensor())

train_loader = torch.utils.data.DataLoader(dataset=train_dataset,batch_size=batch_size,shuffle=True)
test_loader = torch.utils.data.DataLoader(dataset=test_dataset,batch_size=batch_size,shuffle=False)

print(train_loader)
# example = iter(test_loader)
# example_data,example_targets = example.next()

# for i in range(6):
#   plt.subplot(2,3,i+1)
#   plt.imshow(example_data[i][0],cmap="gray")

# img_grid = torchvision.utils.make_grid(example_data)
# writer.add_image('mnist_images',img_grid)

# writer.close()
# sys.exit()

class DeepNeuralNet(nn.Module):
  def __init__(self,input_size,hidden_size,num_classes):
    super(DeepNeuralNet,self).__init__()
    self.l1 = nn.Linear(input_size,hidden_size)
    self.relu = nn.ReLU()
    self.l2 = nn.Linear(hidden_size,num_classes)

  def forward(self,x):
    out = self.l1(x)
    out = self.relu(out)
    out = self.l2(out)
    return out

model = DeepNeuralNet(input_size,hidden_size,num_classes)

compute_loss = nn.CrossEntropyLoss()
optimizer = torch.optim.Adam(model.parameters(),lr = learning_rate)

n_total_steps = len(train_loader)

for epoch in range(num_epoch):
  for i,(images,labels) in enumerate(train_loader):
    images = images.reshape(-1,784)

    output = model(images)
    loss = compute_loss(output,labels)
    loss.backward()
    optimizer.step()
    optimizer.zero_grad()

    if (i+1)%100==0:
      print(f'epochs = {epoch+1} : step = {i+1} : loss = {loss}')

with torch.no_grad():
  n_correct = 0
  n_samples = 0

  for inputs,labels in test_loader:
    inputs = inputs.reshape(-1,784)
    output = model(inputs)
    _, prediction = torch.max(output,1)
    n_samples += labels.shape[0]
    n_correct += (prediction==labels).sum().item()

print(n_correct,n_samples)
accuracy = (n_correct*100)/n_samples

print(f'Accuracy = {accuracy}')



